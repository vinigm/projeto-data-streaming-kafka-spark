# üöÄ Guia de Setup - An√°lise de Sentimento com BERT

## üì¶ O que foi implementado

### PONTO 1: Keywords Expandidas ‚úÖ
- **67 palavras-chave** organizadas em 6 categorias sem√¢nticas
- Cada post agora √© classificado nas categorias: opera√ß√£o, pol√≠cia, viol√™ncia, atores, locais, rea√ß√£o
- Metadados enriquecidos enviados ao Kafka

### PONTO 2: Modelo Transformer BERT ‚úÖ
- Modelo: `lxyuan/distilbert-base-multilingual-cased-sentiments-student`
- An√°lise de sentimento estado da arte
- Suporta portugu√™s brasileiro nativamente

---

## üîß Instala√ß√£o das Depend√™ncias

### 1. Instalar bibliotecas no ambiente Python local (Coletor)
```powershell
pip install atproto kafka-python
```

### 2. Instalar PyTorch e Transformers no container Spark
```powershell
# Entrar no container Spark Master
docker exec -it spark-master bash

# Dentro do container:
pip install torch transformers

# Sair do container
exit
```

**Nota:** Se voc√™ tiver GPU dispon√≠vel, pode instalar a vers√£o CUDA do PyTorch para acelerar:
```bash
pip install torch --index-url https://download.pytorch.org/whl/cu118
```

---

## üéØ Modelos BERT Dispon√≠veis

Voc√™ pode trocar o modelo editando a linha no `processador_spark.py`:

```python
BERT_MODEL = "lxyuan/distilbert-base-multilingual-cased-sentiments-student"
```

### Op√ß√µes de modelos:

| Modelo | Idioma | Velocidade | Acur√°cia | Tamanho |
|--------|--------|------------|----------|---------|
| `lxyuan/distilbert-base-multilingual-cased-sentiments-student` | Multil√≠ngue | ‚ö°‚ö°‚ö° R√°pido | ‚≠ê‚≠ê‚≠ê Bom | 256 MB |
| `neuralmind/bert-base-portuguese-cased` | PT-BR | ‚ö°‚ö° M√©dio | ‚≠ê‚≠ê‚≠ê‚≠ê Excelente | 421 MB |
| `cardiffnlp/twitter-xlm-roberta-base-sentiment` | Multil√≠ngue (Twitter) | ‚ö°‚ö° M√©dio | ‚≠ê‚≠ê‚≠ê‚≠ê Excelente | 1.1 GB |

**Recomenda√ß√£o para Mestrado:** Use o `neuralmind/bert-base-portuguese-cased` para melhor acur√°cia em PT-BR.

---

## üö¶ Como Executar

### 1. Iniciar os servi√ßos Docker
```powershell
docker-compose up -d
```

### 2. Iniciar o Coletor (Terminal 2)
```powershell
python coletor_bluesky.py
```

Agora voc√™ ver√° sa√≠das como:
```
== POST FILTRADO ENCONTRADO ==
Usu√°rio: did:plc:abc123...
Texto: Opera√ß√£o do BOPE na Rocinha causou p√¢nico
Categorias: ['operacao', 'policia', 'violencia', 'locais', 'reacao']
-> Enviado para o Kafka
```

### 3. Iniciar o Processador Spark (Terminal 3)
```powershell
docker exec -it spark-master /opt/spark/bin/spark-submit `
  --master spark://spark-master:7077 `
  --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1 `
  /opt/spark/apps/processador_spark.py
```

**ATEN√á√ÉO:** Na primeira execu√ß√£o, o modelo BERT ser√° baixado (~256MB). Isso pode levar alguns minutos.

---

## üìä Sa√≠da Esperada

O processador Spark mostrar√°:
```
Carregando modelo BERT: lxyuan/distilbert-base-multilingual-cased-sentiments-student
Modelo carregado com sucesso! Usando device: cpu
--- Lendo do t√≥pico Kafka: posts_bluesky ---

[BERT] Sentimento: NEGATIVO (confian√ßa: 87.34%)

+-------------------+------------------+----------------------------------------+-------------------+-----------+
|timestamp_iso      |user_did          |text                                    |categorias         |sentimento |
+-------------------+------------------+----------------------------------------+-------------------+-----------+
|2025-11-15T10:30:00|did:plc:abc123... |Opera√ß√£o do BOPE causou p√¢nico...       |{operacao=true,... |NEGATIVO   |
+-------------------+------------------+----------------------------------------+-------------------+-----------+
```

---

## üéì Configura√ß√µes Avan√ßadas para Mestrado

### 1. Usar GPU (Se dispon√≠vel)
Edite o `processador_spark.py` e o modelo automaticamente detectar√° CUDA:
```python
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
```

### 2. Ativar An√°lise H√≠brida (Regras + BERT)
Troque no `processador_spark.py` linha ~160:
```python
# De:
sentiment_udf = udf(perform_sentiment_analysis_bert, StringType())

# Para:
sentiment_udf = udf(perform_sentiment_analysis_hybrid, StringType())
```

Isso ativa regras espec√≠ficas para casos conhecidos + BERT para o resto.

### 3. Ajustar Categorias M√≠nimas
Para reduzir ru√≠do, voc√™ pode filtrar posts que n√£o tenham pelo menos 2 categorias.

Adicione no `coletor_bluesky.py` antes de enviar ao Kafka:
```python
# Contar quantas categorias est√£o presentes
num_categorias = sum(categorias.values())

# S√≥ enviar se tiver pelo menos 2 categorias
if num_categorias >= 2:
    producer.send(KAFKA_TOPIC, post_data)
```

---

## üêõ Troubleshooting

### Erro: "No module named 'torch'"
```powershell
docker exec -it spark-master pip install torch transformers
```

### Erro: "CUDA out of memory"
O modelo √© muito grande para sua GPU. Use CPU:
```python
device = torch.device("cpu")
```

### An√°lise muito lenta
- Use o modelo `lxyuan/distilbert...` (mais r√°pido)
- Ou adicione mais workers Spark
- Ou use GPU

### Modelo demora para carregar na primeira vez
Normal! O Hugging Face baixa ~256MB. Espere 2-5 minutos.

---

## üìà Pr√≥ximos Passos para Seu Mestrado

1. **Valida√ß√£o Manual:** Anote manualmente 200-300 posts para calcular acur√°cia
2. **M√©tricas:** Implemente c√°lculo de Precision, Recall, F1-Score
3. **Visualiza√ß√£o:** Conecte a um dashboard (Grafana, Kibana)
4. **Armazenamento:** Salve resultados em banco de dados (PostgreSQL, MongoDB)
5. **An√°lise Temporal:** Adicione agrega√ß√µes por janelas de tempo
6. **Geolocaliza√ß√£o:** Extraia e mapeie os locais mencionados
7. **Topic Modeling:** Use LDA ou BERTopic para descobrir t√≥picos emergentes

---

## üìö Refer√™ncias

- [Hugging Face Models](https://huggingface.co/models?pipeline_tag=text-classification&language=pt)
- [Transformers Documentation](https://huggingface.co/docs/transformers/index)
- [PySpark Structured Streaming](https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html)

---

**Boa sorte com seu mestrado! üéì**
